# TensorTalk
A SSL-TTS framework 

Each of these notebooks comprises a core component of our project. The `Train_GlowTTS.ipynb` notebook contains all the training code that we used to attempt to train the GlowTTS model. The `Pipeline_with_GlowTTS_(no_urhythmic).ipynb` notebook contains the original pipeline we proposed using the GlowTTS model. The `Project Pipeline.ipynb` notebook contains our final pipeline, as well as all of its parts, and the functions we used to test it. The `sampled_sentences2.csv` file contains all of the sentences we used for testing and the `examples` folder contains demos of audio generated to sound like the LJSpeech speaker.

## Example Usage
Note: When running the pip installs and imports for the notebooks, you will be prompted with a warning to restart the runtime. Do not restart you runtime and discard the warning.

To test out the `Train_GlowTTS.ipynb` notebook, you can simply upload the best model file, or alternatively comment out the checkpoint loading lines in the main function (at the end). Then you can run all cells, which will download the LJSpeech dataset and begin training the model. You can see the outputs of training from the main cell.

To test out the `Pipeline_with_GlowTTS_(no_urhythmic).ipynb` notebook, run all cells before the last two. These last two cells are here for example usage. The second to last cell shows how you can input text to our TextToSSL model, which uses GlowTTS, and get out WavLM features. The last cell shows how you can input text and target audio to the full pipeline to have it generate a audio file. The third to last cell loads the LJSpeech dataset, which you can use as target audio files. Due to our difficulties training the GlowTTS model, the output of this pipeline is not the best. However, we have attached our best model we got from training, and with more training this GlowTTS pipeline would be able to produce the same results as the final pipeline we used for testing. This pipeline is here to show that our intended framework works without errors, the GlowTTS just needs more training to produce better results. 

To test out the `Project Pipeline.ipynb` notebook, you can run the blocks under SSL Encoder, Vocoder, Urhythmic Component and finally Pipeline. Then you can run the cell under LJSpeech dataset to load up the dataset to use as target audio files. After that you can run the cell under LJSpeech wavs, upload the sampled sentences into the colab, and run the Example Audio Generation cell. You might have to modify where the pipeline saves the generated audio files, but that is all. This example audio generation shows how we generated the audio we used for testing. If you wish, feel free to try to use the model to generate audio of your own sentences. As long as you run the cell putting the LJSpeech file paths into a list you can use this as target audio to generate your own sentences. Below these cells you can see our testing section. This section contains all the code we used for testing, which you can try out if you upload the example folder containing our LJSpeech demos into the colab and change the parent directory in each metric cell. After running the cells you will have data frames containing each metric for all of the example files.

## Contributions
We had 4 members contribute to this project: Alexandre Dalban, Robert Richenburg, Arun Raja, and Alexander Sharpe. Each notebook was mainly worked on by certain members, however all members contributed to each notebook to some degree. Alexandre Dalban worked mainly on the `Train_GlowTTS.ipynb` notebook. Arun Raja worked mainly on the `Pipeline_with_GlowTTS_(no_urhythmic).ipynb` notebook. Alexander Sharpe and Robert Richenburg worked mainly on the `Project Pipeline.ipynb` notebook.